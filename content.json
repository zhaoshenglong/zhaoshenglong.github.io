{"pages":[],"posts":[{"title":"Deploy linux kernel on QEMU","text":"本文主要是记录我第一次使用 Qemu 运行 Linux kernel 的过程。整个过程包括下载、编译、制作根文件系统、编写 init 脚本几个步骤。由于是第一次使用 Qemu 运行 linux kernel，难免会有些问题，希望不要误导大家。 1. Introduction本文章主要是分享我在初次接触使用 Qemu 运行编译后的 linux kernel 的经验。由于是新手，文中难免有错误，敬请批评指正 2. 开发环境首先我们需要有一个宿主机，也就是用来运行 Qemu*，编译 *Linux 的主机。我在本文中主要是使用的 vmware 虚拟机，系统是 Ubuntu 18.04 LTS。 下载必须的开发工具，包括 Qemu，Linux kernel，gcc 等等 2.1 下载安装 Qemu在 Qemu 官网上下载 Qemu 源码，版本可以选择最新的 stable 版本，我在本次实验中选择的是 Qemu v4.2.1 下载好之后，需要编译安装。 这里可以直接按照 Qemu 官网上的安装教程做，命令也不复杂，只是由于使用的都是默认的配置，因此会将大部分的工具都编译安装，编译过程会比较慢。 12345wget https://download.qemu.org/qemu-4.2.1.tar.xztar xvJf qemu-5.1.0-rc1.tar.xzcd qemu-5.1.0-rc1./configuremake 编译完成后，默认是不会将工具安装到系统中的，所有的可执行文件都在下载解压后的目录中，运行虚拟机所需要的可执行文件也在该目录中，对应于 &lt;平台&gt;-softmmu 目录中，比如 x86_64 平台的虚拟机在 x86_64-softmmu 目录中，aarch64 平台的虚拟机在 aarch64-softmmu目录中。 为了方便直接引用目标平台的可执行虚拟机文件（以下都以x86-64为例），我们可以创建 qemu-system-x86_64 的软链接，将这个软链接文件放在 PATH 中。ln -s &lt;绝对路径&gt;/qemu-4.2.1/x86_64-softmmu/qemu-system-x86_64 /usr/bin/qemu-system-x86_64 2.2 下载 Linux kernel下载 Linux 内核 在 github 或者 kernel.org 上下载即可，推荐下载 LTS 的内核版本，可以在 kernel.org 2.3 利用 busybox 制作内存根文件系统","link":"/2020/07/21/Deploy-linux-kernel-on-QEMU/"},{"title":"Flexible System Call Scheduling with Exception-Less System Calls","text":"1. 摘要本篇论文主要介绍的一种新型 系统调用 思路。 传统系统调用主要是通过内核提供入口，用户态调用时通过特殊的机器指令和相应的寄存器进入内核执行相关的函数调用。而本篇论文提出的新型系统调用主要是一种依赖于共享内存、后台内核线程技术的函数调用，这种函数调用不需要用户态陷入内核，而这样子做的好处主要是能够提高用户态代码的locality 本篇论文的首先会评测分析传统系统调用在 system intensive workloads 下对性能的严重影响；在基于这种现象的观察基础上，作者提出了新型系统调用，并对其设计实现进行了阐述；最后作者在 Apache、MySQL上应用了新型系统调用，来评测分析这种修改对性能的提升效果。 2. 设计实现2.1 传统系统调用及性能问题传统系统调用是用户态用来和 kernel 通信的主要方式，依赖于同步的调用模型，在系统调用完成之前，应用程序无法进行用户态的执行。 传统系统调用的问题主要是，在一些系统调用密集的工作负载下，从用户态切换刀内核态执行，将会破坏应用态的 locality，对 locality 的破坏将会严重的影响应用程序的性能。 2.2 exception-less system call显然，传统系统调用的问题主要就是对 locality 的破坏，导致硬件的利用率差，而 locality 的破坏主要是由于用户态和内核态的切换导致的，即主要是由于 exception-based execution mode l造成的。 本文提出了一种 exception-less system call。用户态和内核态之间共享一个 syscall page，用户态将系统调用的请求写入这个共享内存，内核态的特殊线程（syscall threads）负责处理这个共享内存的所有请求。 2.2.1 设计exception-less system call 的设计包含两方面 提供给用户态线程一个注册 system calls 的接口 提供一个异步的内核态线程系统，负责处理 system calls 2.2.1.1 用户态接口 syscall page syscall page 是内核态和用户态之间共享的内存，主要用来存放 系统调用 entry。用户态应用程序在需要系统调用时，需要在这段内存中寻找一个空闲的 entry，然后填入相应的字段。 syscall entry 包含的字段主要有：syscall number、arguments、status [free / submitted / busy / done]、result syscall number number of arguments status arg1 … arg6 return value 4Byte 2Byte 2Byte 8Byte … 8Byte 8Byte 2.2.1.2 内核态异步执行线程exception-less system call 不会主动通知内核有系统调用请求，因此内核态需要一种机制来异步处理这种请求，这种在内核态下专门处理系统调用请求的线程被称作 syscall thread。 syscall threads 只有在用户态线程无法继续执行的时候才会被唤醒，然后执行请求。 syscall threads 可以被调度在和用户态线程不同的 core 上，以此来提高用户态线程的 locality。 2.2.2 实现在 exception-less syscall 的实现中还需要2个使用 传统系统调用 方式的系统调用接口：flex_register 和 flex_wait，这两个系统调用接口主要是作为扩展，用来启用 FlexSC（即本文实现的exception-less syscall） 的接口 2.2.2.1 flex_registerflex_register 主要是用户态用来启用 FlexSC 的接口，当用户态的进程需要使用 FlexSC 时，应当在 process 创建时，调用这个系统调用。 flex_register 的执行逻辑主要包含2部分 在内核态映射 syscall pages 到用户态 为每一个syscall entry创建一个syscall threads 2.2.2.2 flex_waitflex_wait 也是一个传统系统调用，用来在用户态线程无法继续执行的情况下，主动通知内核唤醒 syscall threads 处理系统调用请求。当有至少一个 syscall 完成，就可以唤醒用户态由于无法继续执行而进入等待的线程。","link":"/2020/07/08/Paper-Reading-FlexSC-Flexible-System-Call-Scheduling-with-Exception-Less-System-Calls/"},{"title":"日记:记一个不是很开心的周六","text":"上午参加了学校组织的 129冬季长跑 ，和协会里的战友一起跑了十公里。 跑之前，大家都说配速5-6分钟，结果跑起来配速4′40。 我第一个五公里感觉还能跟上，结果第二个五公里刚开始就系鞋带，然后就掉队了，最后只能看着他们一起冲线，而我却只能一个人默默的过线。 配速不是特别快，但是对于我甲亢一年多没运动的人来说，这是这几年来第二个十公里，还是有点难度。第一个十公里是一个星期前的练习，当时跑了52分钟，配速大概5’11″。 但是让我难过的并不是我没有跟上队伍的步伐，真正让我难过的是，我在第二个五公里自己的意志力不够坚强，满脑子都是想休息，然后出列系鞋带，最后就没有再追上队伍。可笑的是，刚开始跑的时候，我还说了一句，“谁要是掉队了，就说一句，大家一起拖你”。最后就我一个人掉队了，哈哈哈 :cry: 跑完后和好朋友一起拍了照，每次拍照还是笑得傻傻的，哈哈哈。 右边的是我 让我比较佩服的是有一个退伍很久的学长，第一圈感觉他已经坚持不住了，但是最后还是和大队伍一起坚持跑下来了，意志力远胜于我。怪不得他能成为交大年度人物，还是专业第一。 让我引以为傲的意志力也被打到了，甲亢一年多来，自己真的是越来越差。 下午和协会的大家一起拍宣传照，协会里的人都很好。 今天一天都很充实，也很难过。","link":"/2020/12/05/%E6%97%A5%E8%AE%B0-%E8%AE%B0%E4%B8%80%E4%B8%AA%E4%B8%8D%E6%98%AF%E5%BE%88%E5%BC%80%E5%BF%83%E7%9A%84%E5%91%A8%E5%85%AD/"},{"title":"C++1X: quick sort using C++1X features","text":"近年来，C++ 不断发展，新的标准不断涌现，而我还停留在把 C++ 当成 具有面向对象特性的 C 来看待和使用。新的 C++ 标准给我们带来了很多特性，并且能够使得我们的代码变得更加简洁。 这篇文章是我第一次学习使用 C++ 11/14/17 特性时的笔记，希望使用 C++ 11/14/17 特性写一个泛型的 quick sort 函数。","link":"/2020/12/07/C-1X-quick-sort-using-C-1X-features/"},{"title":"Paper Reading: Cooperation and Security Isolation of Library OSes for Multi-Process Applications","text":"","link":"/2020/12/06/Paper-Reading-Cooperation-and-Security-Isolation-of-Library-OSes-for-Multi-Process-Applications/"},{"title":"Run unmodified c++ program under the support of graphene-sgx","text":"SGX 是 Intel 近几年来才有的硬件安全特性，可以将应用放在一段加密内存中保护起来。在 SGX 的保护下即使 VMM、Kernel 完全被攻击者挟持，也无法攻击其中的应用。 但是 SGX 有一套自己的编程规范，需要定义 edl 文件，并且需要比较细粒度的对应用进行切分，划分 Trust/Untrust，这对编程人员来说造成了一定的困难。而 Graphene-SGX 则是 Graphene 的作者和 Intel 的专家合作开发的 libOS，可以在不修改应用的情况下将其运行在 SGX 中。 本文主要是记录我在学习使用 Graphene-SGX 时，第一次成功运行 c++ 的 hello-world 程序的过程。 安装 GrapheneGraphene 是 oscarlab 在 libOS 上的工作研究。在 EuroSys’14 上，该实验室发表了 Graphene 的相关研究成果。在 Intel SGX 出现后，在 ATC’17 上该实验室又和 Intel 合作发表了 Graphene-SGX 的相关研究成果。目前 Graphene 已经在 github 上开源，repo 地址：https://github.com/oscarlab/graphene Graphene 的官方文档中对于如何使用介绍的内容比较少（也可能是我没读懂），我主要是通过学习其中的 example 摸索出如何使用这个 libOS。 根据文档的提示，首先下载 graphene ，可以通过 git clone https://github.com/oscarlab/graphene.git 的方式。 因为需要 graphene-sgx 的特性，因此 host 机器上必须安装 Intel-sgx-driver，以记 Intel-sgxsdk 文档在这一块的说明比较详细，有以下几点需要注意： 按照文档的说明，graphene-sgx 需要 Linux kernel 开启 FSGSBASE 特性，因此可能需要编译更新 kernel， 打 patch。 clone 下来的 graphene 有一个 submodule 引用了 graphene-sgx-driver , 因此需要运行 git submodule update --init -- Pal/src/host/Linux-SGX/sgx-driver/。 在文档 Quick Start 中的第 3 步中，注释提示，terminal 可能会要求我们输入 path to the Intel SGX driver code，这里其实就是输入 sgx.h 头文件的目录所在，可以在 Intel sgx driver 的安装目录找到 sgx.h，然后把目录复制过来就好。 1234cd $GRAPHENE_DIRmake SGX=1# the console will prompt you for the path to the Intel SGX driver code# (simply press ENTER if you use the in-kernel Intel SGX driver) 所有都编译成功后，运行 Quick Start 中的 test 也通过了，就说明安装成功了。 使用 Graphene-SGX接下来就可以自己学习写一个 manifest，来运行我们的 c++ program。 第一次使用，我运行的程序比较简单，是 c++ 版的 hello-world, 代码如下： 12345#include &lt;iostream&gt;int main() { std::cout &lt;&lt; &quot;Hello, test!&quot; &lt;&lt; std::endl;} 代码写好之后，我们就需要写一个 Makefile 文件，这里主要是需要参考 Examples/ 目录下的示例。 Makefile 编写12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364# Use one of these commands to build the manifest for Bash:## - make# - make DEBUG=1# - make SGX=1# - make SGX=1 DEBUG=1## Use `make clean` to remove Graphene-generated files.# Relative path to Graphene root and key for enclave signingGRAPHENEDIR ?= ../..SGX_SIGNER_KEY ?= $(GRAPHENEDIR)/Pal/src/host/Linux-SGX/signer/enclave-key.pemifeq ($(DEBUG),1)GRAPHENEDEBUG = inlineelseGRAPHENEDEBUG = noneendif.PHONY: allall: test.manifest | test pal_loaderifeq ($(SGX),1)all: test.tokenendifinclude ../../Scripts/Makefile.configs# Generating manifest rules for Bash dependenciesstest.manifest: manifest.template sed -e 's|$$(GRAPHENEDIR)|'&quot;$(GRAPHENEDIR)&quot;'|g' \\ -e 's|$$(GRAPHENEDEBUG)|'&quot;$(GRAPHENEDEBUG)&quot;'|g' \\ -e 's|$$(ARCH_LIBDIR)|'&quot;$(ARCH_LIBDIR)&quot;'|g' \\ $&lt; &gt; $@# Generating the SGX-specific manifest (*.manifest.sgx), the enclave signature,# and the token for enclave initialization.test.manifest.sgx: test.manifest $(GRAPHENEDIR)/Pal/src/host/Linux-SGX/signer/pal-sgx-sign \\ -exec test \\ -libpal $(GRAPHENEDIR)/Runtime/libpal-Linux-SGX.so \\ -key $(SGX_SIGNER_KEY) \\ -manifest test.manifest -output $@test.sig: test.manifest.sgxtest.token: test.sig $(GRAPHENEDIR)/Pal/src/host/Linux-SGX/signer/pal-sgx-get-token \\ -output test.token -sig test.sigtest: g++ test.cpp -o $@pal_loader: ln -s $(GRAPHENEDIR)/Runtime/pal_loader $@.PHONY: all.PHONY: cleanclean: $(RM) *.manifest *.manifest.sgx *.token *.sig test pal_loader.PHONY: distcleandistclean: clean 第 11 行 - 第 26 行基本上是 Examples 中的公共部分，这里主要是定义了一些变量，后面将会使用。 在 SGX enabled 时，需要生成的目标文件一共有：*.manifest, *.manifest.sgx, *.sig, *.token, *, pal_loader *.manifest: 该文件主要是定义了 graphene 创建隔离环境时需要挂载的文件、挂载的地方、环境变量等等。具体的将会在后一节内容详细介绍。 *.manifest.sgx: 该文件是在 *.manifest 的基础上对依赖的 trusted_files 进行了签名，以用于加载到 enclave 时进行完整性检查。 *.sig: *.token: *.pal_loader: Manifest 编写Manifest 中主要定义一些 Graphene 需要挂载的库、挂载的路径，环境变量，SGX 相关配置，SGX 信任的文件等等。 General 部分12345678910111213loader.argv0_override = &quot;$(ARGV0_OVERRIDE)&quot;# Read application arguments directly from the command line. Don't use this on production!loader.insecure__use_cmdline_argv = 1# Graphene environment, including the path of the library OS and the debug# option (inline/none).loader.preload = &quot;file:$(GRAPHENEDIR)/Runtime/libsysdb.so&quot;loader.debug_type = &quot;$(GRAPHENEDEBUG)&quot;# Environment variablesloader.env.LD_LIBRARY_PATH = &quot;/lib:$(ARCH_LIBDIR)::/usr/lib/x86_64-linux-gnu&quot;loader.env.PATH = &quot;/&quot; 第 1 行的 loader.argv0_override 是指在运行 ./pal_loader xxx 时，用 xxx 来代替 pal_loader，也就是运行这个 xxx 程序的意思。 第 11 行的 loader.env.LD_LIBRARY_PATH 指定了程序运行时需要的库加载路径，我猜想，程序运行时应该需要到这些路径上去搜索库。 Mount 部分12345678910111213141516171819202122# Mounted FSes. The following &quot;chroot&quot; FSes mount a part of the host FS into the# guest. Other parts of the host FS will not be available in the guest.# Default glibc files, mounted from the Runtime directory in GRAPHENEDIR.fs.mount.lib1.type = &quot;chroot&quot;fs.mount.lib1.path = &quot;/lib&quot;fs.mount.lib1.uri = &quot;file:$(GRAPHENEDIR)/Runtime&quot;# stdc++ files, mounted from /usr/lib/ARCHfs.mount.lib2.type = &quot;chroot&quot;fs.mount.lib2.path = &quot;/usr/lib/x86_64-linux-gnu&quot;fs.mount.lib2.uri = &quot;file:/usr/lib/x86_64-linux-gnu&quot;# Mount host-OS directory contanining libcrypt and NSS libraries.fs.mount.lib3.type = &quot;chroot&quot;fs.mount.lib3.path = &quot;$(ARCH_LIBDIR)&quot;fs.mount.lib3.uri = &quot;file:$(ARCH_LIBDIR)&quot;# Mount /binfs.mount.bin.type = &quot;chroot&quot;fs.mount.bin.path = &quot;/bin&quot;fs.mount.bin.uri = &quot;file:/bin&quot; 接下来就是挂载，可以看到，在这次使用中，我挂载了四个目录，之所以这样，是因为 hello-world 这个程序的依赖包含了不同路径的库。 要检查某个程序依赖哪些库，可以通过 ldd xxx 来查看，ldd xxx 的结果应该都需要挂载到 graphene 中。 manifest 中所有的 bash-like variable 都需要在 Makefile 中将其替换成字面量。这个也是 *.manifest 目标文件生成时所需要做的主要工作。可以看到，在这个 Makefile 中，主要是通过 sed -e 's|xx|'xx'|g' 来完成的。 SGX 部分1234567891011121314151617181920212223242526# Set the virtual memory size of the SGX enclave. For SGX v1, the enclave# size must be specified during signing. If the program needs more virtual# memory than the enclave size, Graphene will not be able to allocate it.sgx.enclave_size = &quot;256M&quot;# Set the maximum number of enclave threads. For SGX v1, the number of enclave# TCSes must be specified during signing, so the application cannot use more# threads than the number of TCSes. Note that Graphene also creates an internal# thread for handling inter-process communication (IPC), and potentially another# thread for asynchronous events. Therefore, the actual number of threads that# the application can create is (sgx.thread_num - 2).sgx.thread_num = 4# SGX trusted libraries# Glibc librariessgx.trusted_files.ld = &quot;file:$(GRAPHENEDIR)/Runtime/ld-linux-x86-64.so.2&quot;sgx.trusted_files.libc = &quot;file:$(GRAPHENEDIR)/Runtime/libc.so.6&quot;sgx.trusted_files.libm = &quot;file:$(GRAPHENEDIR)/Runtime/libm.so.6&quot;sgx.trusted_files.libdl = &quot;file:$(GRAPHENEDIR)/Runtime/libdl.so.2&quot;sgx.trusted_files.librt = &quot;file:$(GRAPHENEDIR)/Runtime/librt.so.1&quot;sgx.trusted_files.libutil = &quot;file:$(GRAPHENEDIR)/Runtime/libutil.so.1&quot;sgx.trusted_files.libpthread = &quot;file:$(GRAPHENEDIR)/Runtime/libpthread.so.0&quot;# stdc++ librariessgx.trusted_files.libstdcpp = &quot;file:/usr/lib/x86_64-linux-gnu/libstdc++.so.6&quot;sgx.trusted_files.libgcc_s = &quot;file:/lib/x86_64-linux-gnu/libgcc_s.so.1&quot; 最后，sgx 部分主要需要配置 enclave 的相关参数，这和 SGX 编程模型中的 xml 配置文件的配置基本一致。 sgx.trusted_files.[identifier] 是在程序运行时需要加载的库，可以通过 ldd 来查看，应该是每一个依赖都需要列举在此处。但是由于我是第一次使用，所以也只能凭感觉，如果有错误，希望大家能指出！ 编译运行编写好之后，就可以通过简单的命令直接运行我们的 hello-world 程序。 12SGX=1 makeSGX=1 ./pal_loader test 如果一些顺利，将会输出 Hello, test! 哈哈哈，这是很简单的一个program，但是成功输出的时候，真的很开心！ 参考 Graphene 官方文档 https://graphene.readthedocs.io/en/latest/quickstart.html GNU Make 文档 https://www.gnu.org/software/make/manual/make.html Intel SGX 文档 https://download.01.org/intel-sgx/linux-1.7/docs/Intel_SGX_SDK_Developer_Reference_Linux_1.7_Open_Source.pdf","link":"/2020/12/14/Run-unmodified-c-program-under-the-support-of-graphene-sgx/"},{"title":"Linux命令行小白入门教程","text":"本篇文章的目标读者是 Linux 小白用户，也就是从未接触过 Linux，对于命令行是什么都不了解的新手~ 是相当基础的新手村教程思密达~ 对于 Linux 有一定了解的可以不用往下继续看啦 : ) 什么是命令行？命令行，英文名是 command line，你看，翻译过来是不是就是 命令 行，一个字都不错！那么什么是命令行呢？ 你在看一些和黑客有关的电影的时候是不是经常看到这样的场景：电脑屏幕上黑漆漆的，一些不知道是什么东西的文字在屏幕上滚动，比如下面这张图 其实，这就是黑客在使用命令行就行一些 hacking 的操作，比如通过一些工具扫描远程主机的端口信息、连接到远程主机、编写一些程序、登录远程主机、获取远程主机的控制权等等（这些我是都不会啦，哈哈哈，我只会一点命令行的皮毛） 在没有图形界面时，命令行是人们和电脑交互的主要方式，通过输入一些字符，执行一些程序。但是这个对于普通用户十分不用好，图形总是比文字更加生动形象，所以图形界面的出现使得电脑开始普及。但是对于程序员来说，命令行是必须要了解的工具之一哦~ 使用命令行能做很多图形界面做起来不是很方便的事情！ 有哪些命令行呀！ Windows 上的命令行 Windows 在最初是 DOS 系统，开机之后就进入一个黑黑的界面，用户可以在这个黑黑的界面输入命令，回车执行。比如下面这个图，dir 命令会显示当前位置（C:\\）的文件，ver 命令则会显示 DOS 的版本信息。 这个黑黑的界面看起来是不是有点熟悉，如果不觉得熟悉也没关系，尝试一下下面的操作 按 win + r（windows 键和 r 键一起按），会出现 运行 程序 在这个 运行 程序中输入 cmd，确定，就会打开 Windows 系统的 命令行界面，打开之后应该是下面这个样子： 尝试在这个 cmd 程序中输入 ver ，然后按回车，看看有什么输出。再试一下输入 dir ，然后回车，看看有什么输出！ ver 输出了 Windows系统 版本信息，dir 列出了 C:\\Users\\ALIENWARE 下的文件！ 真棒！ Linux 上的命令行 在 Linux 上命令行也被称作 terminal， 有英文自然会有中文，所以也会有人叫做 终端，初次之外还有诸如 sh, shell , bash, dash, zsh 等等的称呼，叫法虽然不一样，但是大致上都是相似的。 shell 是 terminal 的一种，而 sh、bash、dash、zsh 则是不同的 shell 。之所以会有这么多不同的 shell，主要是因为 Linux 是完全开源的操作系统，在 Linux 内核上，有许多人添加了不同的软件（桌面、浏览器、下载工具、软件管家等等）形成了不同的发行版系统（比如 Ubuntu、RedHat、CentOS、ArchLinux 等等），在这些不同的发行版 Linux 系统中，也就根据不同的需求制作了不太一样的 shell。不过虽然名字不太一样，大体上还是相似滴。 以 Ubuntu 18.04 操作系统为例 （不是 18.04 的也没关系） 使用鼠标右键 Open terminal 打开终端，打开后会出现和下图类似的界面。 尝试输入 ls 命令，看看会输出什么！想一想 ls 和 Windows 的 cmd 哪一条命令比较像？ 哈哈哈，你也太棒了！ VScode 的命令行 在 VScode 上的命令行实际上是打开了系统的命令行，不同的是 VScode 的命令行会嵌入 VScode 中，但是效果其实都是一样的哦~ 命令行的基本介绍（以ubuntu bash为例） 打开命令行之后，你就进入了一个目录中（可以理解成文件夹中）。这就像你打开了文档管理器，比如你打开了 test 文件夹，这个文件夹下面有 dir 文件夹，还有一个 readme.txt 。 12345test文件夹下：├── dir│ ├── dir.txt│ └── script.sh└── readme.txt 在文档管理器中，我现在处于 test 文件夹，我想返回上一级文件夹，就可以通过点击上级文件夹。而如果我想去 dir 文件夹，就可以双击 dir 文件夹。 而在命令行中，也是可以做到同样的事情的！比如，如果我想返回上一级文件夹，我就可以输入以下命令 1cd .. 这样，我就会回到上一级文件夹（其实叫做目录更准确一点，但是你不必纠结，windows 里叫做文件夹，而 Linux 里一般叫做目录）。这里 .. 的意思其实就是上一级目录。除此以外 . 代表当前目录。输入下面的指令练习一下吧！ 12345678# 以#开头的是注释，在命令行里输入不会有任何效果。# 当前目录是 test/cd .. # 当前目录是 test的父目录cd . # 当前目录还是 test 的父目录cd test # 当前目录是 test/cd dir # 档期那目录是 test/dircd .. # 当前目录又变成了testcd ../test/dir/.. # 想一想，这条命令执行完之后，当前目录是什么？ 你肯定可以想出来！ 在命令行里执行的指令其实都是一个程序，比如 cd 其实是一个程序，bash在发现你输入的是 cd 后，就会去找这个程序，如果找到了就会执行这个程序，如果没有找到，就会跟你抱怨：“这个程序我没有找到！”，脾气好一点的还会跟你提一些建议，“你是不是输错了”，也有时候会提醒你，“你没有安装这个程序，可以通过以下方式安装该程序。” 命令行基本命令介绍（以 ubuntu bash 为例）命令行里可以执行很多指令，每个指令都是一个程序，只要 bash 知道这个程序存在，那么你就可以输入这条指令。今天我们先来学习一下几个强大但又不复杂的指令吧！ ls ls 指令可以列出当前目录下的所有文件。ls 其实是 list 的简称，程序员在起名字的时候都会尽量简单以避免打太多字，哈哈哈。 这个指令可以在你不知道当前目录下有哪些文件的时候使用。 12345test文件夹下：├── dir│ ├── dir.txt│ └── script.sh└── readme.txt 还是以这个 test 文件夹为例，输入以下命令试一试！ 123456789# 当前目录 testls# &gt; dir readme.txtls dir# &gt; dir.txt script.shls --help# 输出了 ls 命令的帮助信息# 哇！ 现在屏幕都是乱七八糟的信息，太烦了，我想清理屏幕！clear # 这个命令可以将bash的输出全部清除~ 聪明的你肯定已经发现了，ls 指令后面可以跟着目录，这样会把那个目录的文件信息罗列出来~ cd cd 命令是 change directory 的简称，可以在命令行里切换目录。cd 的强大你应该已经了解啦，我就不多介绍了~ mkdir mkdir 命令是 make directory 的简称，顾名思义，这个命令时创建目录（文件夹）的。快来使用下面的命令尝试一下 1234567891011# test/ 目录下mkdir dir1ls# &gt; dir dir1 readme.txtls dir1# &gt; empty 没有输出，因为 dir1 是空文件夹mkdir dir1/dir1ls # &gt; dir dir1 readme.txtls dir1# &gt; dir1 刚刚创建的 dir1/dir1 出现了！ touch touch 命令可以用于创建普通文件（不是目录的文件），touch 命令后面要跟着文件的名称哦~ 1234567# test/ 目录下touch test.txtls # &gt; dir dir1 readme.txt test.txttouch testls # &gt; dir dir1 readme.txt test test.txt 真棒！ 你已经学会如何创建文件、文件夹、查看文件夹里的文件啦！可是刚创建了几个文件，想要删除文件怎么办呢？看看下面的 rm 命令吧！ rm rm 命令时 remove 的简称，顾名思义是删除的意思，可以用来删除指定的文件/目录 12345678910# test 目录下ls# &gt; dir dir1 readme.txt test test.txtrm test test.txt # 删除 test、test.txt 文件ls# &gt; dir dir1 readme.txtrm dir1# &gt; rm: cannot remove 'dir1/': Is a directoryls # &gt; dir dir1 readme.txt 咦，奇怪，我想要删除 dir1 文件夹，可是 bash 说了一句 rm: cannot remove 'dir1/': Is a directory 和之前好像不太一样呢，然后 ls 查看 dir1 还是存在啊，怎么回事！ 这是因为，rm 一般情况下只能删除普通文件，也就是不是目录的文件。那要怎么删除目录文件呢？ 123456# test目录下ls# &gt; dir dir1 readme.txtrm -r dir1ls# &gt; dir readme.txt 啊哈！成功删除了，真棒！rm -r 可以删除指定的目录！学会啦！ 命令行后续学习后续的学习就需要勇士自己探索啦，就像打游戏，怎么点技能，怎么加天赋都需要你自己摸索才有意思，不一样的是，打游戏培养的是游戏角色，学习命令行，培养的是勇士自己！ 注意命令行的信息，仔细阅读，如果出现了和正确情况不一致的信息，命令行的都会提示你的。比如下面的图 bash 告诉我们 cannot access 'test': No such file or directory 这句英文的意思就是无法访问 test，没有这个文件或目录。 再比如下面这个图，我输入了 brew 命令后，bash 告诉我这些信息。从这些信息中可以看到，bash 找不到这个 brew 命令，同时还告诉我可以通过 sudo apt install linuxbrew-wrapper 来安装 brew ！ bash 真是太贴心了！ 有的时候，bash 的报错信息我读不懂，怎么办呢？ 当遇到这种情况的时候，就可以将报错信息复制下来，然后去 google/百度上搜索啦！ 总之，命令行的学习需要探索，需要查各种攻略，尝试各种技能搭配，相信一定能学好的！","link":"/2020/12/23/Linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B0%8F%E7%99%BD%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"},{"title":"C++ Primer: Basics","text":"本篇博客主要记录我在阅读 《C++ Primer》一书的 Basics 部分时学习到的以前未留意的知识点。主要包含 Chapter 2 Variables and Basic Types 和 Chapter 3 Strings, Vectors, and Arrays Chapter 1. Variables and Basic Types String literal Two string literals taht appear adjacent to one another and taht are separated only by spaces, tabs, or newlines are concatenated into a single literal. We use this form of literal when we need to write a literal that would otherwise be too large to fit comfortably on a single line 字符串字面量可以邻接，编译器在处理的时候会将这些字符串字面量连接起来。 比如下面的代码是合法的 12std::cout &lt;&lt; &quot;a really, really long string literal&quot; &quot;that spans two lines&quot; &lt;&lt; std::endl; 看到这里，我又想起在 C 中也有相同的用法，比如在 Linux kernel 中的 printk 函数，在打印的时候可以指定日志级别，KERN_INFO, KERN_DEBUG, KERN_ERR ,KERN_ALERT 等等都是使用 #define 指令定义的字符串字面量，在 printk 时可以使用这些宏定义。 1printk(KERN_INFO &quot;This is really, really an info from kernl&quot;) List Initialization Built-in 类型也可以使用 List initialization 进行初始化。List initialization 是 C++ 11 的新特性，可以用作对象的初始化。对于 Built-in 类型的初始化需要注意，不能有精度缺失，否则会报错。 比如下面的初始化均是合法的： 1234int units_sold = 0;int units_sold = {0};int units_sold{0};int units_sold(0); 而下面的初始化是会报错的： 123long double ld = 3.1415926536;int a{ld}, b = {ld}; // error: narrowing conversion requiredint c(ld), d = ld; // ok: but value will be truncated 可见，在对于 built-in 类型进行 花括号 初始化时，是不能有信息丢失的。:question: 这里是否可以说是不能自动类型转换？（尚未考证） Variable initialization 对于 built-in类型 来说， 定义在函数体外的变量会被默认初始化为 0 ，而定义在函数体内的变量默认是不会初始化的，这些变量的值是未定义的。 函数体外的变量，一般也就是全局变量，在编译链接的时候会被放在 .bss 段内，所以会被初始化为 0 。而函数体内的变量，可能来自于寄存器，也可能来自栈，无论来自哪里，值都是不确定的。因此，函数体内的变量在声明后比较好的做法是进行初始化。 而对于 class 类型 的变量，则由该类的初始化方法决定，对于初始化方法中没有进行初始化的成员变量，将会采取和上述策略进行初始化（即如果不在函数体内，built-in 类型初始化为0，class由类决定；在函数体内，built-in 类型不进行初始化，class依旧由类决定） 比如下面的代码： 1234567891011121314151617181920212223#include&lt;iostream&gt;#include &lt;string&gt;using namespace std;class Test {public: int a; int *b; string s; friend ostream&amp; operator&lt;&lt;(ostream&amp; os, const Test&amp; t) { os &lt;&lt; &quot;a: &quot; &lt;&lt; t.a &lt;&lt; &quot; p: &quot; &lt;&lt; t.b &lt;&lt; &quot; s: &quot; &lt;&lt; t.s; return os; }};Test gt;int main() { Test lt; std::cout &lt;&lt; gt &lt;&lt; endl &lt;&lt; lt &lt;&lt; endl ;} 在不提供构造方法的时候，Test gt 和 Test lt 都会调用类的默认初始化方法，因此，gt 和 lt 都是合法的 object，可以引用。但是由于默认初始化方法不会对成员变量进行初始化，因此这里 gt 的几个成员变量将会被初始化，a, b 会被初始化为 0，而 s 会调用 string 的构造函数，初始化为 &quot;&quot; 空字符串。而 lt 的几个成员变量则因为在函数体内，a, b 不会被初始化，因此是未定义的值，而 string s 一样会调用构造函数，初始化成 “”空字符串。 所以，编译这个程序，将可能输出以下的内容： 123./a.out# a: 0 p: 0 s: # a: 1524593168 p: 0x55f8bfb60da7 s: 当 Test 提供构造函数，初始化成员变量后，才能保证即使在函数体内，成员变量也是初始化的~ Scope 显示的引用全局作用域可以使用作用域操作符 :: 。全局作用域是没有名字的，因此可以通过 ::test 显示引用全局作用域下的 test 对象。 123456789101112#include &lt;iostream&gt;using std::cout;using std::endl;int test = 10;int main() { int test = 5; cout &lt;&lt; test &lt;&lt; endl; // 5 cout &lt;&lt; ::test &lt;&lt; endl; // 10;} Pointers &amp; References 指针和引用都是对其他对象的间接引用。 不一样的是： reference 情根深种，从初始化之后就不能再更改引用的对象；而 pointer 在其生命中可以引用不同的对象。 reference 从出生就和引用的对象绑定在了一起，它本身并不是一个object，而是一个 alias；pointer 则是自由的，就连出生的时候也不需要指定对象。因此，reference 是不存在地址的，对 reference 的寻址，其实都是对 reference 引用的对象的寻址。 123456int a = 10; // a is an int type valeint &amp;b = a; // b is a reference to aint *c = &amp;a; // c is a pointer to aint *d = &amp;b; // d is a pointer to a, here &amp;b is &amp;a actuallyassert c == d; // ok 此外，reference 在初始化时必须和所引用的对象类型一致，除了有两种例外情况： referece to const 一类的引用。可以引用能转换成这个 Reference 类型一致的表达式。比如， 123int a = 10;const int &amp;b = a; // ok, because `int` can be converted to `const int` const int &amp;c = 1.23 // ok, because `1.23(double)` can be converted to `const int` reference to base-class 一类的引用。可以使用 Pet &amp; 来引用 Cat 1234567891011121314151617181920212223#include &lt;iostream&gt;#include &lt;string&gt;using std::cout;using std::endl;using std::string;class Pet {public: string name; Pet(string name) : name(name) {}};class Cat : public Pet {public: Cat(string name) : Pet(name){}};int main() { Cat cat(&quot;miao~&quot;); Pet &amp;pet = cat; cout &lt;&lt; pet.name &lt;&lt; endl; // miao~} Const const 变量默认是只对所定义的那个文件可见的，即默认是 static 的。如果需要在其他文件使用，则在定义时需要添加 extern 关键字。 12345678910111213141516171819202122232425262728// file1.cpp#include &lt;string&gt;const int num = 10;extern const std::string word = &quot;Hello, world!&quot;;// file2.cpp#include &lt;string&gt;#include &lt;iostream&gt;extern const int num;extern const std::string word;int main() { std::cout &lt;&lt; num &lt;&lt; &quot; &quot; &lt;&lt; word &lt;&lt; std::endl; return 0;}// g++ file1.cpp file2.cpp// output:// file2.cpp:(.text+0x6): undefined reference to `num'// fix by change the definition // `const int num = 10;` to // `extern const int num = 10;`// g++ file1.cpp file2.cpp// ./a.out// =&gt; 10 Hello, world! 正如前面提到的，reference to const 可以使用和定义 reference 类型不一致但是可以通过类型转换得到的对象。比如前面的 const int &amp;c = 1.23 。对于这一点，C++ Primer 的作者进行了进一步的解释。 编译器在处理类型转换时，需要首先转换成临时变量，再赋值给目标对象的。也就是说对于 const int &amp;c = 1.23 ，编译器的处理会分为两步 1. const int db = 1.23； 2. const int &amp;c = db; 由于是 reference to const ，因此这里无法更改 c 引用的对象。 但是，如果允许非 const 的引用类型转换，比如 int &amp;c = 1.23 // error ，分两步就会变成形如 int tmp = 1.23; int &amp; c = tmp; 如此一来，由于 c 不是 reference to const， 因此可以改动 c 引用的对象的值，于是编译器创建的临时变量的值就会被更改，而这显然和 reference 语义不相符。 作者还提到了 top-level const 和 low-level const， 对于指针来说，top-level const 表示这个 pointer 本身是个 const, low-level const 则是表示这个 pointer 指向了一个 const 的对象。 当复制一个对象的时候，可以忽略 top-level const， 因为复制这个动作并不会改变被复制的对象。 1234int a = 10;int *const p1 = &amp;a; // p1 is a const pointer which points to `int a`int *p2 = p1 // ok 但是在复制的时候，low-level const 是不可以忽略的，low-level const 的对象不能复制给一个 非 low-level const 的变量。 1234int a = 10;const int *p1 = &amp;a; // p1 is a pointer which points to `const int`;int *p2 = p1 // error: invalid conversion from 'const int*' to 'int* auto auto 类型修饰的变量必须进行初始化，这个还是比较容易理解的，不进行初始化，编译器没法推导变量类型。 此外，auto 变量推导的类型还有几个需要注意的点： 当使用 reference 作为 initializer 时，编译器将会使用 reference 引用的对象的类型作为 auto 推导的类型。 auto 的 initializer 会忽略掉 top-level const， 但是 low-level const 不可忽略。 auto 不会推导 const 类型，如果需要 const 的 auto 变量，需要显示声明 const， 比如const auto a = 1; decltype decltype 是 C++11 的新特性，可以用来定义根据表达式或变量推到的类型的变量。 12decltype(1) a; // intdecltype(1+4.9) b // double 值得注意的是，decltype 并不会计算表达式，仅仅是编译时进行静态分析。 如果 decltype 里是变量的话，将会返回那个变量的类型，包括 top-level const 和 reference； 如果 decltype 里是表达式的话，将会返回这个表达式生成的对象的类型。 12345int i = 42, *p = &amp;i, &amp;r = i;decltype(r + 0) b; // intdecltype(*p) c; // error: because *p returns int&amp;decltype(i) d; // error: int&amp; must be initializeddecltype((i)) e; // error: (i) returns int&amp;, e must be initialized constexpr Chapter 2. Strings, Vectors, and Arrays Vector initialization 常见的初始化方式就不记录啦，这里记录两个不是很常见的初始化方式 vector&lt;string&gt; vec(10); 比如上面的表达式初始化长度为 10 的向量，每个元素都会被默认初始化。 需要注意的是， 如果这个 vector 装载的元素是没有默认初始化方法的话，就不能仅仅定义长度，而必须在明确长度的同时，明确初始化的数据。 vector&lt;string&gt; vec{&quot;hello&quot;, &quot;test&quot;, &quot;world&quot;, &quot;!&quot;}; 这种初始化方式是 C++11 的新特性，当列表中的元素都是符合 vector 装载的类型的时候，会将这些元素挨个添加进入向量。当有元素无法转成 vector 装载的类型的时候，比如这里 vector&lt;string&gt; vec{10, &quot;test&quot;}， 就会尝试调用 vector&lt;string&gt; vec(10, &quot;test&quot;) 的方法来初始化。 Vector range for 当使用 vector 的 range for 语句时，循环体不能改变向量的大小。 Iterator iterator 分为两种，一种是 iterator， 可以读写所引用的对象；另一种是 const_iterator，只能读取引用的对象。 在写代码的过程中，一般使用 auto 进行自动类型推导，可以不必了解 iterator 的具体细节。 12345string s = &quot;123&quot;;const string cs = &quot;456&quot;;auto it = s.begin(); // string::iteratorauto cit = cs.begin(); // string::const_iterator 这里可以看到，begin() 函数返回的 iterator 会根据对象的类型返回 iterator 类型或者 const_iterator 类型。在 C++11 之后，有 cbegin() 方法，可以显示的返回 const_iterator 类型的迭代器。 所有 iterator 支持 ++, --, ==, != 操作，但是 vector 和 string 还多支持了一些其它的算术逻辑操作。 123456it + nit - nit += n it -= nit1 - it2 &gt;, &gt;=, &lt;, &lt;= // 用于比较同一个 container 中的迭代器引用的元素顺序先后 Arrays array 和 vector 最主要的区别在于，array 的大小是固定的，不可以动态更改。 array 可以使用 列表初始化 方式进行初始化。在进行初始化的时候，可以不指定 array 的大小， 如果指定了 array 的大小，那么初始化的时候，元素数量必须不大于指定的大小。如果用于初始化的元素数量小于指定的大小，不足的部分将会被默认初始化。 1234int a1[] = {0, 1, 2} // size 为 3 的 arrayint a2[3] = {0, 1, 2}int a3[3] = {} // 相当于 int a3[] = {0, 0, 0}int a4[3] = {0, 1, 2, 3} // error: 用于初始化的元素数量大于数组大小 ​","link":"/2021/01/06/C-Primer-Basics/"},{"title":"Linear Algebra 1: Determinant","text":"本篇博客主要是关于《线性代数》的一些基础知识，主要参考 bilibili 上《线性代数》高清教学视频 “惊叹号”系列 宋浩老师 系列视频。文章中不会每个细节都记录，主要是记录以免彻底遗忘。另外，博主并不是数学专业，最后一次学习数学已经是5年前了，所以难免会有疏漏，还请各位看到批评指正！ 行列式行列式，记作 $$det(A)$$ 或者 $$|A|$$ ，是一个在方阵 (NxN 阶矩阵) 上计算得到的标量。可以用来确定线性方程组解的个数（无解/0个解/无数解） 二阶行列式二阶行列式比较简单，大致的形式如右边所示： $$\\left|\\begin{array}{cccc} a &amp; b\\ c &amp; d\\end{array}\\right|$$ 这样的二阶行列式计算起来也比较容易，比如上面的行列式的计算就是 $$ad - bc$$ 三阶行列式","link":"/2021/01/25/Linear-Algebra-1-%C2%96Determinant/"},{"title":"C++ Primer: Functions","text":"本篇博客主要记录《C++ Primer》一书的第六章 Functions 的相关知识点 Arugment Passing 在定义函数时，如果参数不同是可以重载函数的。但是如果参数时指针/数组，就会容易出现一些小问题。 123void print(const int*) {}/* void print(const int[]) {} *//* void print(const int[10]) {} */ 比如以上的代码，无论是数组，还是指针参数，其实在处理的时候都会被当成指针来处理，也就是上面的三个看起来参数不同的函数，其实是同一个函数定义。如果取消掉注释，编译的时候是会报重定义的错误的。 那么如果参数不是数组指针，而是数组引用呢？ 123/* void print(int (&amp;arr)[]) {} */void print(int (&amp;arr)[2]) {}void print(int (&amp;arr)[10]) {} 上面的函数定义其实并不会报重定义的错误，因为参数是不同的，是不同长度的数组引用。值得注意的是，由于是引用，如果不指定长度是会报错的。 在调用上面定义的函数时，也需要注意，对于参数是长度为2的数组引用，传入的数组必须是长度为2的，同样，对于参数是长度为10的数组引用，传入的数组也必须是长度为10的数组。 varying parameters C 的方法（不建议使用） 在C中可以使用 ... 来代表可变长参数来定义函数。这个 ... 实际上利用了 C 库的 varargs initializer_list 列表参数方法 定义函数时将可变长的部分用 initializer_list&lt;type&gt; xxx 来定义，在使用的时候，通过传入 {xxx, xxx, xxx} 来传递可变长参数。值得注意的是，这个initializer_list 中传递的参数都是 const 的，是不可以改变的，这一点和使用 vector 是不同的，也更加符合参数的语义。 举例来说，使用方法大概如下 12345678910void error_msg(initializer_list&lt;string&gt; il) { for (auto&amp; elem: il) { cout &lt;&lt; elem &lt;&lt; &quot; &quot;; } cout &lt;&lt; endl; }int main() { error_msg({&quot;This&quot;， &quot;is&quot;, &quot;a&quot;, &quot;test&quot;});} variadic template return type 在 C/C++ 中，如果函数返回一个指向数组的指针，写法是比较奇怪的。 123int (*func())[] { // ...} 要避免这种不太容易识别的写法也是可以的。这本书里提到了很多方法，在 C++11 之前，可以使用 typedef 来定义类型别名，当然使用 using 也是可以的。 123typedef int arrT[];using arrT = int[];arrT *func(int i); 除此以外，还可以使用 trailing return type 的方式，就是在函数参数列表之后使用 -&gt; 类型 的方式来表示返回类型。 1auto func(int i) -&gt; int (*)[]; overloading 定义重载函数必须保证参数数量或者参数类型不一样，否则会造成重定义。这里有个值得注意的地方，当参数被 const 修饰的时候，const 必须是 low-level const， top-level const 是会被忽略的，因此对于被 top-level const 修饰和未被修饰的参数重载函数会被认为是重定义。 123456789int func(int);int func(const int); // 重定义int func(int *);int func(int* const); // 重定义int func(int &amp;);int func(const int &amp;); // okint func(int *);int func(const int*); // ok default arguments 默认参数在进行赋值的时候，除了不能使用局部变量，其他表达式都能使用。 inline inline 函数是程序员希望这个函数会被 compiler 展开，但是 compiler 并不会满足所有的 inline 请求，是否会进行转化还是要看 compiler 的。 constexpr functions","link":"/2021/02/27/C-Primer-Functions/"},{"title":"Paper Reading: A Security Architecture with CUstimizable and Resilient Enclaves","text":"本篇论文是达姆城工业大学的教授 Ahmad Sadeghi 和他的学生发表的 TEE 相关的论文。论文主要是介绍并实现了一个新型的 TEE，支持多种类型的Enclave，对外设的的访问控制，并针对侧信道攻击进行了防护。 IntroductionTEE (Trusted Execution Environment) 可以提供强有力的隔离可信执行环境 —— enclave。但是现有的 TEE 解决方案有许多设计上的不足： 现有的 TEE 都仅提供了一种 “通用” enclave 类型。比如 SGX 仅仅提供了 user-space enclave，内核态无法使用 enclave，ARM TrustZone 提供了 secure world 和 normal world，secure world 内可以运行一个 small kernel，但是问题是 TrustZone 只有这一个 enclave，如果要为用户态提供 enclave，需要自己扩展。（enclave 类型少） 对新兴的应用支持度不够，比如对 Machine Learning as a Service 这种需要使用外设/多核算力的程序来说，现有的 TEE 支持都不好。（外设/多核支持度差） 普遍无法防御 side-channel attacks，即使有防御手段也是亡羊补牢的解决方案。（侧信道攻击防御差） 针对以上问题，本篇论文的作者提出了一个新型的 TEE 架构 —— CURE，CURE 相比现有的 TEE，解决了以上的不足，主要的特性有以下几点： 支持多种类型的 enclave： user-space enclave、kernel-space enclave、sub-space enclave 支持 enclave 和外设等资源的绑定 针对侧信道攻击进行了防御，在 shared-cache 上提供了按需的 way-based cache 隔离，而在 core-exclusive cache 也做了一定的防御 CURE Architecture我们先来组略的看一下 CURE 的架构。 正如下图所示，CURE 共有三个特权级 —— PL0, PL2, PL3（当然这只是 CURE 架构的一种实现而已，可以根据不同的体系结构进行更改）。这里值得注意的是，在 PL0 特权级运行了 Firmware，并且这个 Firmware 中的一部分是 SM（Secure Monitor），而这个 Secure Monitor 运行在 enclave 中。SM 是 CURE 中非常重要的角色，是绝对不可以被攻陷的组件。正如 Secure Monitor 这个名字指示的一样，SM 的任务主要是监控管理所有的 enclave，enclave 安装、启动、运行、关闭都离不开它。 图1. Enclave 类型 那么 SM 在 enclave 的安装、启动、运行、关闭中担当的任务有哪些呢？ enclave 安装enclave 的安装和大多数 TEE 类似，SM 会检查 enclave 的完整性，如果验证成功，SM 会为该 enclave 创建一个 元数据结构 $D_{encl}$ ，$D_{encl}$ 主要包含以下几个内容： $L_{encl}$ —— enclave 的 label，全局唯一，由 service provider （发布这个 enclave 的人）提供 $Sig_{encl}$ —— service provider 提供的 enclave 签名，用来校验完整性 $Cert_p$ —— service provider 的公钥证书，用于检查 service provider 的身份 $S_{encl}$ —— enclave state structure，包含该 enclave 的所有敏感数据，用来持久化 $K_{encl}$ —— 加密 $S_{encl}$ 的密钥 counter —— 用来防止 rollback $D_{encl}$ 以及一些其它的信息会存放在 $S_{sm}$ 中，$S_{sm}$ 记录 SM 的相关状态信息。 enclave 启动和关闭启动enclave 的启动总是由 host app 来触发。然后 OS 从持久化存储设备上加载 enclave 和 配置文件，随后 OS 会跳转到 SM，将执行权交给 SM。 SM 会首先检查 enclave 和配置文件的完整性，随后会根据配置文件的需求给 enclave 配置硬件来分配一段或多段连续的物理内存区域。 随后，SM 会根据配置文件分配其他的系统资源，比如 cache，外设等等。这些也是通过配置硬件来实现的。 所有给 enclave 分配的资源都会记录在 $D_{encl}$ 中。此外，SM 会为这个新启动的 enclave 分配一个唯一的 ID，这个 ID 在所有正存活的 enclave 中唯一。这个 ID 在 enclave 隔离中的作用非常重要。 最后，SM 会从存储设备中 $S_{encl}$， 并检查 $S_{encl}$ 中的 counter 和 $D_{encl}$ 中的 counter 是否一致。这一步主要的目的是防止 rollback attack。 总结起来，enclave 的启动过程大致如下图所示： 图2. enclave 启动流程 在启动配置 enclave 的时候，SM 是不会被中断的，这个可以通过配置关闭其他所有的 CPU 的中断来实现。此外，hyperthreading 在 CURE 中是关闭的，否则可能会导致部分共享资源的泄露。 SM 在启动 enclave 的时候，会配置 enclave 的所有 中断都转发到 SM，这样 SM 就完全控制了 enclave 的上下文切换。 在 enclave 启动过程中，有几点值得注意 有很多地方都需要 SM 来配置硬件，那么应该如何配置呢？ 配置硬件的目的又是什么？ SM 为每一个存活的 enclave 都分配了一个 ID，这个 ID 起到了什么作用？ 关闭enclave 的卸载比较简单，SM 首先将 $S_{encl}$ 和 $ D_{encl}$ 中的 counter 加1，然后将 enclave 的状态 $S_{encl}$ 保存起来（加密） enclave 执行enclave 执行时，大多数情况下和普通程序没有什么区别，但是一旦有 中断/异常 等需要进行上下文切换时，SM 就会拦截并进行一些检查。 此外，enclave 在进行上下文切换，启动和关闭时， SM 会强制 flush 所有 core-exclusive cache，也就是 L1 icache 及 L1 dcache（如果 L2-cache 也是 core-exclusive，也需要刷新）。这样做的目的是防止新切换的程序（无论是 enclave 还是 host app）窃取 cache 中的一些信息。那么，为什么 LLC (Last Level Cache) 不需要刷新呢？ enclave 的三种类型CURE 中主要有三种类型的 enclave。正如图1所示，其中 $Encl_1$ 是 user-space enclave; $Encl_2, Encl_3$ 则是 kernel-space enclave；$Encl_4$ 是 sub-space enclave。 user-space enclaveuser-space enclave 运行在用户态，和普通程序一样，user-space enclave 依赖 OS 进行内存管理，异常中断处理，调度。 此外，为了防止类似 controller side-channel attack 的侧信道攻击，user-space enclave 将 page table 放在 enclave memory 中，以防止被攻击者观察。 那么问题来了，page table 在 enclave memory 中，OS 如何做内存管理呢？ kernel-space enclavekernel-space enclave 运行在内核态，也可以包含用户态的部分。由于运行在内核态，所以 kernel-space enclave 可以不依赖 OS 提供的服务，而采用自己定义的 RunTime 接口，这样更加安全，但同时也增加了 enclave 的大小。 sub-space enclavesub-space enclave 允许将一个特权级内的软件的部分构建成 enclave （这里我总有点不太理解，和普通的切分程序来划分 可信/不可信 部分有什么区别呢）。 sub-space enclave 最有用的地方在于可以在最高特权级构建一个绝对可信的 TCB，并且降低 TCB。比如，在 CURE 中，SM 就是这样一个 sub-space enclave。 CURE 硬件配置在前面的介绍中，有很多细节问题没有解释清楚，比如 enclave id 有什么用；如何配置硬件；enclave 的内存管理究竟如何做到；资源隔离又是如何保证的等等，下面将会一一进行解答 enclave id eid 是 CURE 中用来代表 enclave 运行上下文的标识。在 CURE 的设计中，eid 存储在每一个 CPU 核上的寄存器中，而这个 eid register 中的值就表示了当前这个核上正在运行的 enclave 是谁。在每一次 enclave 启动/关闭/上下文切换时，eid register 都会重新设置。 此外，eid 主要用来做访问控制，eid 会附加在 bus transaction 中。 在 CURE 实现中， 一个 eid 4 bit，一共有 16个 ID，并且 OS 的 ID 为 0，SM 的 ID 为 0xF，Firmware 的 ID 为 0xE。 memory isolation enclave 的 memory 是由 SM 分配的连续物理内存，每当 CPU 发出内存请求时，main memory 的 arbiter 就会通过 bus transaction 中的 eid 和 添加在 arbiter 的寄存器来判断是否有权限访问。添加在 arbiter 的寄存器主要用来存放 enclave 对应的内存区域，假设一共有 16 个enclave，每个enclave 有一段 物理内存，那么就有 16 个寄存器。 在 CURE 的实现中，一个 enclave 分配一段连续的物理内存，内存的布局如下图所示。 page table 是放在 enclave memory 中的。在 enclave 启动时，OS 像创建普通进程一样创建页表，不同的是，OS 会将所有的内存都映射好，而不使用 demand paging；随后，OS 将 page table 传给 SM，SM将其拷贝至 enclave memory中，并修改 OS 的 satp 寄存器 (页表基地址寄存器)。此后，OS 不可以再修改页表，因为所有对页表的访问都会被 main memory arbiter 拦截。当需要分配新的内存时，会触发 page fault，OS 会将执行权交给 SM。 peripheral binding 在 CURE 中，CPU访问外设时，bus transaction 也会携带 eid 信息，和内存隔离相似，在 外设 的 arbiter 也需要检查当前正在运行的 enclave 是否有权限访问这个外设对应的 MMIO 区域。 在 CURE 的实现中， 每个外设都添加了两个寄存器，一个表示这个外设的 MMIO 区域，另一个则表示了每一个 enclave 的读写权限。 DMA protection CURE 在每个 DMA 设备的 decoder 前都添加了寄存器，这些寄存器定义了 DMA 设备可以访问的内存区域。 cache protection 针对 core-exclusive cache，由于 CURE 在每一个 enclave 上下文切换/启动/关闭 都会刷新，因此攻击面不大。因此，在 CURE 中，作者们只做了一种基本的检查。作者们扩展了每个 cache entry，增加了 4-bit 的 line-eid，表示这个 cache line 所属于的 enclave， 每个enclave 只允许访问属于他的 cache line。 而针对 shared-cache，CURE 使用了一种 on-demand way-based partition 策略。 EvaluationSystem modificationsSoftware 作者们总结了 CURE 对软件的修改，可以看到总共也只有3KLOCs。而最重要的 SM 只有 500 行代码，因此作者们可以做形式化验证，并且降低了 TCB。 Hardware由于作者们使用的 Rocket-chip generator 设计的 CURE 架构，因此硬件测试时是使用的生成的 verilog 进行的测试。 从上图中可以看到，硬件修改上的开销上面也很小。 Performance overhead性能测试方面，作者们是使用的 FPGA 进行的 cycle-accurate 仿真模拟测试。 作者们首先进行了 单核 的性能测试，测试结果如下： 测试结果显示，在单核情况下， user-space enclave 的平均性能开销是 19.70%，而 kernel-space enclave 的平均性能开销是 15.33%。 在多核的测试下，作者们针对 kernel-space enclave 进行了测试，测试工具是 stree-ng，测试结果显示，多核下的 kernel-space enclave 的性能和普通进程的性能差不多","link":"/2021/02/28/Paper-Reading-A-Security-Architecture-with-CUstimizable-and-Resilient-Enclaves/"},{"title":"C++ Primer: Classes","text":"本篇博客主要记录的是 《C++ Primer》第七章 classes 的相关知识点，主要记录我以前不太了解的部分，由于我对 C++ 的理解不是很深刻，难免会有理解不正确的地方，如果给屏幕前的你带来困惑，实属抱歉，还望不吝指正~ 1.","link":"/2021/03/06/C-Primer-Classes/"},{"title":"Paper Reading: Efficient Multi-client Isolation Under Adversarial Programs","text":"本篇论文是 Purdue university 和首尔国立大学合作研究的成果。论文主要针对了 multi-client 的云服务场景，提出了一种基于 SFI（Software Fault Isolation）的 in-enclave 的线程隔离机制，并进行了详尽的测试和对比分析。论文显示，在 micro-benchmark 下，作者们提出来的这个框架比多进程沙盒隔离机制性能优越 4.06 − 53.70×，而在真实应用场景下，该框架性能优越 0.02 ~ 21.18x。 IntroductionIntel SGX 可以对应用程序和数据提供强有力的保护，enclave 外部很难获取这些数据。但是 enclave 内的程序可能有 bug，甚至有可能是别有用心的人特殊设计来窃取数据的。 那么现有的一些对这种类型的用户数据保护的工作，比如 Ryoan，VC3，都没有提供在一个 enclave 内的隔离机制，都是多个 process 的隔离，这就带来很大的性能开销（page swaps，data redundancy &amp; transferring）。 本文作者提出了一种 面向 multi-client 场景的 in-enclave 隔离方案 —— CHANCEL，主要有以下几点特性： SecureLayer —— CHANCEL 的可信服务 提供 enclave 内的一些功能（文件系统、内存管理、），以此完全控制 enclave 内程序与外界的通讯，并对通信信道进行加密。 可读共享内存区域 —— 这一点对后面的测试很重要 MCSFI (Multi-Client Software Fault Isolation) —— enclave 内部的线程隔离机制 每个线程服务一个 client，且只可以访问 private 的内存区域和 enclave 内的一个只读共享区域。 目标场景 CHANCEL 面向的服务场景有 Private information retrieval，比如提供 health-care 建议的服务。这些服务通过用户的查询，结合一个共享的医疗健康数据库推断用户的健康信息等；比如 intrusion detection system，通过比较分析 packet 和预定义的 signature dictionary 来辨别木马等病毒。 现有工作及其问题 Ryoan 保护面有限，没有线程隔离（因为是多进程的隔离，这点也是本文主要比较对象之一，SGX下，多线程性能优于多进程） 硬件普适性不强，MPX 技术已经不再支持，而 SGX2 还没有落地。 没有针对 multi-client 场景进行隔离 Threat ModelCHANCEL 的威胁模型认为，service provider 可能故意窃取用户的数据；cloud provider 或者攻击者可能控制程序，但是程序的功能看起来是正常的。CHANCEL 的目的就是防止一个使用多线程来服务用户的远程程序泄露用户数据。 DesignOverview service provider 使用 CHANCEL 提供的工具进行编译插桩；在云上部署enclave环境并运行 SecureLayer；然后将 service program 上传到云上，SecureLayer 对上传的程序进行反汇编检查，确保符合安全要求； 当 SecureLayer 收到 client 请求时，会在可用的线程和 client 之间建立一个安全信道（比如通过 Diffie-Hellman 密钥交换） MCSFIMemory Layout MCSFI 的内存分布除了 enclave 本身之外，还包括 每个线程分配一个专用的私有区域； 所有线程共享的只读区域（只有在初始化程序的时候是可写的） 额外的可执行区域（service） SecureLayer 的内存区域包含 attestation 和 validation 的程序和数据，用来正确加载程序；thread i 内存区域是专属于 thread i 的；sgx.code 是目标程序的内存区域；sgx.shared 是所有线程共享的内存区域。 MCSFI 要求在编译时期就为线程预留好空间，这个和 SGX1 的设计类似（SGX1要求确定最大线程数，只允许静态分配的内存）。 权限控制 在加载 service 之前，enclave 内只有硬件权限，即 enclave 内基本上都是可读可写的，所以 SecureLayer 可以在 sgx.code 安装程序 在安装完 service 之后，sgx.code 区域就没有写权限了，这个是由 MCSFI 保证的，此时可以对 sgx.shared 区域进行初始化 在初始化完成后，sgx.shared 区域会变成只读的区域，这个主要也是由 MCSFI 保证的 Compiler instrumentation 首先，CHANCEL 预留了2个通用寄存器，r14 和 r15。r14 保存着 sgx.code 的基地址；而 r15 在初始化 sgx.shared 区域前，保存着 sgx.shared 的基地址，在初始化完成后保存对应 thread 的私有区域基地址。 利用这两个寄存器，一条 load 指令就会被改成 一串指令。首先判断 load 的地址是否大于 r14，如果大于，则访问的是 sgx.shared 内的区域；否则访问的是 thread private 的区域。 如果访问的是 sgx.shared 区域，就可以直接访问；而如果是访问的 thread private 区域，就会将目标地址和 (1GB - 1) 做一个masking，然后再加上 r15 (thread private 区域基地址) ​ :question: 为什么 line 5. 要将目标地址 &amp; (4GB - 1) store 指令的处理类似，但是因为只有 thread private 区域是可读，所以直接和 (1GB - 1) 做一个 masking 即可。 显然，如果要对所有的 load/store 指令都做插桩，性能开销会比较大，而其实有很多内存访问都是基于栈的，因此，CHANCEL 将每个线程的 rsp 放在私有区域内。这样访问的时候就不需要进行插桩修改指令。:question: 这里为什么 rsp 是和 (4GB - 1) 做 masking​ 为了防止程序跳过 instrumentation，CHANCEL 确保所有的跳转目标地址都是 32 bytes 对齐的（通过插入 nop），因此，一个跳转指令会被修改成下面这样： Shared Data Initialization CHANCEL 的编译器提供了一个注解属性，可以通过注解 annotate(“sgx.shared”) 来共享一个全局变量。在加载程序的时候，CHANCEL 会将这个全局变量拷贝到 sgx.shared 区域。 此外，CHANCEL 可以在 sgx.shared 区域为程序提供需要的文件。 Full Mediation CHANCEL 全程参与 client 和 thread 之间的通信，并确保每一个和外界的通信都被加密。此外，CHANCEL 提供了 in-enclave filesystem service 和 dynamic memory allocation。 Evaluation测试环境 4核8线程 Intel i7-6700K CPU 64MB内存，128MB EPC 分为三个部分的测试：1. 和 multi-process 沙盒机制比较性能，主要和 Ryoan 进行比较；2. 测试 CHANCEL 的性能开销；3. 运行真实的程序，并和 Native 的 SGX 及 multi-process 沙盒 进行比较 Compared to multi-process sandbox由于 Ryoan 使用了 SGX2 的硬件技术并且采用的是 QEMU 模拟的系统，所以作者采用的 multi-process sandbox 是 CHANCEL-MP —— CHANCEL 的一种变体，利用多进程隔离 clients。（CHANCEL-MP 和 Ryoan的差别就在于隔离机制不同，CHANCEL的 SFI 隔离机制性能优于 Ryoan） 测试过程 —— 分配 $m$ MB 内存，$n$ 个线程连续访问其中的 512 KB区域的 8 字节 $k$ 次 测试结果 —— CHANCEL 比 CHANCEL-MP 性能优越 4.06x ~ 53.70x Overhead of CHANCEL使用 nbench 在普通环境（non-enclave）进行测试，这样可以避免 EPC 换页导致的额外开销，从而测试 CHANCEL 的真实开销 测试结果 —— 性能开销大概在 0.91% ~ 24.89%，平均大概为 12.43% 测试分析 对于 memory-intensice 的程序来说，性能开销会比较大，比如 NUMERIC SORT，STRING SORT；对于 cpu-intensice 的程序来说，性能开销比较小，比如 IDEA data access 是性能开销的关键原因 保留了 r14, 415，所以寄存器分配时，spill 会增加 instrumentation 带来了额外的指令 Real-world Programs针对真实程序的测试分别使用 4 线程 和 8线程，共享内存大小分为 18MB，36MB，72MB（light workloads），144MB，288MB，576MB（heavy workloads）。 OSSEC 使用 ClamAV 的病毒库，逐步增加库大小（从18MB 到 576MB），CHANCEL 性能优于 CHANCEL-MP 0.21x~ 7.66x。在 light workloads下，Native 和 CHANCEL 的 Page Faults比较少，因此运行时间和字典大小增加几乎是成比例的，而 heavy workloads 虽然CHANCEL 性能影响也很大， 但是相比于 CHANCEL-MP，随着内存的增加，性能优越性更好。 DrugBank 在 light workload 下，CHANCEl 的性能优越性不是很明显，主要是因为 在 light workload 下，每次 hashing 取得的 working set 比较小，所以 page swap 不是很大。相应的，在 heavy workload 下，CHANCEL 性能明显优于 CHANCEL-MP。 Recommender recommender 的情况和 OSSEC 类似，在 light workload 下，Native 和 CHANCEL 的完成时间随着共享内存的增加而增加，这是由于，recommender 的工作集取决于 catalog 大小（共享内存） ShieldStore 测试的结果和 OSSEC 及 Recommender 类似 Snort 测试结果和 DrugBank 类似，在 light workload 下性能优越性不明显（由于 working set 比较小），而在 heavy workload 下性能优越性明显增强。 测试总结CHANCEL 性能比 CHANCEL-MP 优越 0.02x ~ 21.18x，相比于 Native，仅仅导致了 0.2~ 13.1% 的性能开销。","link":"/2021/04/09/Paper-Reading-Efficient-Multi-client-Isolation-Under-Adversarial-Programs/"}],"tags":[{"name":"Linux kernel","slug":"Linux-kernel","link":"/tags/Linux-kernel/"},{"name":"Qemu","slug":"Qemu","link":"/tags/Qemu/"},{"name":"syscall","slug":"syscall","link":"/tags/syscall/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"C++11&#x2F;14&#x2F;17","slug":"C-11-14-17","link":"/tags/C-11-14-17/"},{"name":"Graphene","slug":"Graphene","link":"/tags/Graphene/"},{"name":"libos","slug":"libos","link":"/tags/libos/"},{"name":"EuroSys","slug":"EuroSys","link":"/tags/EuroSys/"},{"name":"SGX","slug":"SGX","link":"/tags/SGX/"},{"name":"Graphehe-sgx","slug":"Graphehe-sgx","link":"/tags/Graphehe-sgx/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Tutorial","slug":"Tutorial","link":"/tags/Tutorial/"},{"name":"杂记","slug":"杂记","link":"/tags/%E6%9D%82%E8%AE%B0/"},{"name":"C++ Primer","slug":"C-Primer","link":"/tags/C-Primer/"},{"name":"Linear Algebra","slug":"Linear-Algebra","link":"/tags/Linear-Algebra/"},{"name":"Determinant","slug":"Determinant","link":"/tags/Determinant/"},{"name":"Security","slug":"Security","link":"/tags/Security/"},{"name":"TEE","slug":"TEE","link":"/tags/TEE/"}],"categories":[{"name":"Paper Reading","slug":"Paper-Reading","link":"/categories/Paper-Reading/"},{"name":"Note","slug":"Note","link":"/categories/Note/"},{"name":"Tutorial","slug":"Tutorial","link":"/categories/Tutorial/"},{"name":"Linux","slug":"Tutorial/Linux","link":"/categories/Tutorial/Linux/"},{"name":"Programming Language","slug":"Programming-Language","link":"/categories/Programming-Language/"},{"name":"Security","slug":"Note/Security","link":"/categories/Note/Security/"},{"name":"杂记","slug":"杂记","link":"/categories/%E6%9D%82%E8%AE%B0/"},{"name":"Reading","slug":"Reading","link":"/categories/Reading/"},{"name":"Math","slug":"Math","link":"/categories/Math/"},{"name":"Linear Algebra","slug":"Math/Linear-Algebra","link":"/categories/Math/Linear-Algebra/"}]}